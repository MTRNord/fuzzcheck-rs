# Status

## Bugs

* errors are not gracefully handled, or even properly explained

* the command line app does not catch signals, so it can't tell
the user which file is the most minified at the end. This may be
solved by only keeping the most minimal version of a file at any point,
or by catching signals and displaying a message

* too much complexity, try to simplify stuff
    * much of the complexity is carried over from when I did not know
    what the fuzzer should support or how to do it best, but now I can 
    remove most of it (TODO: reevaluate this)

* shrink command does not work perfectly, it needs to be run a few times
to properly shrink the corpus (TODO: verify that it is fixed)

## Misc

* build a cargo tool that manages the fuzzcheck dependency automatically
    * for now, that tool performs almost no checks and is not configurable
    at all. I should improve that. Take inspiration from `cargo-fuzz`.

* create default generators for most basic types

* limit maximum size of corpus
    * automatically throw out an input every time another one is added

* implement feature groups
    * a problem is that traced CMP instructions are passed through an arbitrary
    filter (only the number of ones in the XOR of the arguments is taken in 
    consideration, and even then different values may still be considered the 
    same). So potentially useful comparison features are ignored.
    
    * another problem is that trace_cmp features will either be underrated 
    (if only one comparison was recorded -> score = 0.5), or overrated (if 
    many different comparisons were recorded, combined score of features for a
    single PC may go up to 8.0 I think). Ideally, a single trace_cmp would have
    a fixed score and each trace_cmp would share that score. This means we need
    to introduce the concept of “feature groups”. For example, every 
    comparison feature for PC 13 would be placed in the same 
    feature group which has a score of 1.0. So that if only one feature was 
    recorded for a given PC, its score would be 1.0, but if 15 features were 
    recorded, their average score would be (1/15). This is a bit difficult to 
    implement in practice, but should be doable.

    * handling the two problems described before would mean that a different 
    condition for admitting inputs to the pool should be used, as many more
    comparison features would then be recorded, and the current condition 
    (that the input is the simplest to contain any feature) would admit way too
    many inputs. A possible solution is to run a quick estimate of the input’s 
    worth and to only admit high-ranking ones.

    * fixing these problems would also lead to a more correct shrink commnand

    * but it would also slow down the fuzzer significantly, which I think may
    not be bad if the improvements lead to a reduction in the number of 
    iterations needed to find a bug. I have to be careful about the performance 
    though, and should wait until I have set up enough benchmarks to be sure it 
    is worth it.

* do not always push inputs to the end of the pool. Instead, try to fill the 
gaps. Maybe every time an input is deleted, I can push its index to a stack.
When I need to add an input to the pool, I pop the index from the stack first
to check if I can fill a gap isntead of pushing it to the end.

* make an InputGenerator for [u8; N]

* redesign MetadatChange/convert_partial_world_actions. I wrote these things 
quickly and it is a mess

* I would like to change the way generators mutate inputs such that it is not
completely random anymore. Instead, the generator would execute mutations in
order of one mutation is most likely to trigger a bug.

    * so for example, for an `Either<(u64, ())>` that is currently Left(x), the
    first mutation would change it to `Right(())`, and then the following ones
    would always change it to `Left(mutated_x)`.

    * for a `(u16, bool)`, the first mutation would toggle the `bool` part, the
    following ones would mutate the `u16`, and the mutations executed even 
    later would mutate both.

    * the goal is also to never apply twice the same mutation to a given input

    * I think it could speed up fuzzing considerably

    * the early mutations would be obvious and still produce values that are
    close to the original ones. The later mutations would produce values that
    are very different to the original one

    * this does not mean that an input cannot be mutated to a random one 
    anymore, but it would instead be *possible* to order mutations
    deterministically

    * maybe after doing this, I should get rid of `mutation_depth` and the 
    return value of `mutate` should be `()` instead of `bool`
    
    * for `u8`, the first mutations would change the value to one of the
    special values. The following ones would increase it by 1, 2, 3, etc.

    * same for u16 except that maybe some `random` calls should be thrown in 
    there, and maybe it could be increased by 1, 2, 3, ..., 254, 255, 256, 512,
    1024, 2048, 4096, ..., 65_536, 384, 768, 1536, ..., 48_152, etc?. 

    * and same principle for all integers

    * for Vec, 

## Documentation

* document fuzzer.rs, other files
* add more tests, they make for good documentation
* document InputPool with some diagrams?
    * maybe not because maybe I will change the algorithm again, and I have
    better things to spend my time on, it is already documented a little bit

## Tests

* there are some tests for InputMetadataPool, but they should be migrated to 
tests on InputPool and verify more properties

* I'd like to fuzz-check Fuzzcheck. It shouldn't be that complicated in terms
of code. But the logistics of it may be tricky. In particular, I should have 
the option to compile it without sanitizer coverage hooks. 

* try to find out how fuzzcheck handles this kind of program:
  ```
  if x == a { counter += 1 }
  if x == b { counter += 1 }
  if x == c { counter += 1 }
  .
  .
  .
  if counter >= N { crash }
  ```
  My intuition is that it will perform better than before. And that feature 
  groups would make it perform even better.